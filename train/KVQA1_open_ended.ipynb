{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "KVQA1_open_ended.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "history_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/David9857/VQA/blob/main/train/KVQA1_open_ended.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6mdYtS7At_V",
        "outputId": "4c009ae2-560b-42d1-e6ba-5e092e96dd17"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvPQbGRGPV-B"
      },
      "source": [
        "!cp /content/drive/MyDrive/files/data_path.zip /content\n",
        "!unzip data_path.zip \"data/jsons/*\" \"data/pic/*\" \"data/ques_embeddings/bioelmo/*\" \"data/answer_word_frequency.csv\" \"data/answer_word_frequency.xlsx\" -d /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDuBoVBH33Tj"
      },
      "source": [
        "# %%bash\n",
        "# cd /content/drive/MyDrive/data\n",
        "# zip -r knowledge_embs.zip knowledge_embeddings/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XerKDOjK0Mxg"
      },
      "source": [
        "!cp /content/drive/MyDrive/data/knowledge_embs.zip /content/data\n",
        "!unzip /content/data/knowledge_embs.zip -d /content/data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCNEgwH01fAH",
        "outputId": "a33d4a65-251c-4a90-d24b-b21a4fcb2640"
      },
      "source": [
        "!ls /content/data/knowledge_embeddings | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32761\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpuAUB3asbLa"
      },
      "source": [
        "# %cd /content\n",
        "# !unzip data_path.zip \"data/ques_embeddings/bioelmo/*\" -d /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUXGclx9A7Ax"
      },
      "source": [
        "# %cd /content/drive/MyDrive/VQACode"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heHcKvagAs68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a65a649e-465e-46fa-d610-70a0074a7497"
      },
      "source": [
        "%cd /content/drive/MyDrive/VQACode\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import time\n",
        "import pathlib\n",
        "from utils.load_data import DataLoader\n",
        "from utils.evaluation import AnswerEvaluator\n",
        "from utils.training_toolkit import CustomSchedule, loss_function\n",
        "from models.Transformer.transformers import VQATransformer\n",
        "from models.Transformer.masks import create_masks"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/VQACode\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTM_T69yAs7I"
      },
      "source": [
        "### Set up Arguments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0Py6WFwAs7J"
      },
      "source": [
        "num_layers=2\n",
        "d_model=512\n",
        "num_heads=8\n",
        "dff=2048\n",
        "maximum_position_encoding=10000\n",
        "EPOCHS = 30\n",
        "batch_size = 64\n",
        "cnn_type = 'inception'\n",
        "embedding = 'bioelmo'  # choose from ['w2v', 'bioelmo', 'biobert', 'bluebert', 'large_biobert', 'elmo']\n",
        "data_augmentation = True\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJXgN3tzAs7K"
      },
      "source": [
        "####### DO NOT CHANGE VALUES OF THIS BLOCK IF YOU ARE NOT THE DEVELOPER ##########\n",
        "\n",
        "check_point_path = './check_point/transformer/open_ended/' + embedding +'/' + cnn_type + '_' + str(num_layers)\n",
        "saving_folder = './open_ended_results/transformer/' + embedding + '/'\n",
        "save_result_path = saving_folder + cnn_type + '_' + str(num_layers) + '.csv'\n",
        "\n",
        "emb_size = 1024\n",
        "pe_output = 36 + 1\n",
        "MAX_LENGTH = pe_output\n",
        "if cnn_type == 'inception':\n",
        "    img_shape = [299, 299]\n",
        "    img_padding = tf.TensorShape([299, 299, 3])\n",
        "if cnn_type in ['resnet', 'resnet_v2', 'dense_net', 'vgg19']:\n",
        "    img_shape = None\n",
        "    img_padding = tf.TensorShape([224, 224, 3])\n",
        "\n",
        "if embedding == 'bioelmo':\n",
        "    pe_input = 38\n",
        "elif embedding == 'elmo':\n",
        "    pe_input = 42\n",
        "elif embedding == 'biobert':\n",
        "    pe_input = 72\n",
        "    emb_size = 768\n",
        "elif embedding == 'bluebert':\n",
        "    pe_input = 69\n",
        "elif embedding == 'large_biobert':\n",
        "    pe_input = 60  \n",
        "elif embedding == 'w2v':\n",
        "    pe_input = 48\n",
        "    emb_size = 200\n",
        "elif embedding == 'bert':\n",
        "    pe_input = 72\n",
        "    emb_size = 1024\n",
        "else:\n",
        "    raise TypeError(\"Wrong embedding type\")\n",
        "    \n",
        "if data_augmentation:\n",
        "    aug = tf.keras.Sequential([tf.keras.layers.experimental.preprocessing.RandomFlip(),\n",
        "                               tf.keras.layers.experimental.preprocessing.RandomRotation(0.05)])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6FLQdXIAs7L"
      },
      "source": [
        "#### "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SVDCLOfAs7L"
      },
      "source": [
        "### Create Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nslZKpSaAs7M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51eafff5-36ff-4ac0-cb3a-63572a5c91d7"
      },
      "source": [
        "# create train, val, test dataset\n",
        "kn_input = 155\n",
        "\n",
        "data_loader = DataLoader('/content/data', emb_folder=embedding)\n",
        "full_dataset, tokenizer = data_loader.create_dataset('open_ended')\n",
        "vocab_size=len(tokenizer.index_word) + 1\n",
        "Data_SET_SIZE = len(full_dataset)\n",
        "train_size = int(0.52 * Data_SET_SIZE)\n",
        "val_size = int(0.30 * Data_SET_SIZE)\n",
        "test_size = int(0.18 * Data_SET_SIZE)\n",
        "train_set = full_dataset.take(train_size)\n",
        "val_test_ds = full_dataset.skip(train_size)\n",
        "val_set = val_test_ds.take(val_size)\n",
        "test_ds = val_test_ds.skip(val_size)\n",
        "test_set = test_ds.take(test_size)\n",
        "\n",
        "batch_train_set = train_set.padded_batch(batch_size, padded_shapes=((img_padding, tf.TensorShape([pe_input, emb_size]), tf.TensorShape([kn_input, emb_size])),\n",
        "                                            tf.TensorShape([pe_output-1]), []), drop_remainder=True)\n",
        "batch_test_set = test_set.padded_batch(1, padded_shapes=((img_padding, tf.TensorShape([pe_input, emb_size]), tf.TensorShape([kn_input, emb_size])),\n",
        "                                                         tf.TensorShape([pe_output-1]), []), drop_remainder=True)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11111\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbsIenPScgQ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe35f23b-e044-4a1d-da94-d51285dabd80"
      },
      "source": [
        "for i in enumerate(batch_train_set):\n",
        "  (batch, (img_question, tar, q_id)) = i\n",
        "  print(batch,img_question[0].shape,img_question[1].shape,img_question[2].shape,tar.shape,q_id.shape)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 (64, 224, 224, 3) (64, 38, 1024) (64, 155, 1024) (64, 36) (64,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fenPNKce01b"
      },
      "source": [
        "maxl = 0\n",
        "for (img_question, tar, q_id) in full_dataset.as_numpy_iterator():\n",
        "  # print(img_question[0].shape,img_question[1].shape,tar.shape,q_id)\n",
        "  # print(img_question[2].shape)\n",
        "  l = img_question[2].shape[0]\n",
        "  if l > maxl:\n",
        "    maxl = l\n",
        "print(maxl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlpYIPVolVGL"
      },
      "source": [
        "import numpy as np\n",
        "# validate saved features and calculate max length of all questions\n",
        "ques_id = 48\n",
        "emb = np.load('/content/data/ques_embeddings/bioelmo/'+str(ques_id)+'.npy')\n",
        "# length = emb.shape[0]\n",
        "print(ques_id,'shape is', emb.shape)        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZBh6t3pAs7M"
      },
      "source": [
        "### "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cs5vzLoUAs7N"
      },
      "source": [
        "### Define Models and Related Functions "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2HVCXcoAs7N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7612bc4-876f-485e-8929-dba1be19ef71"
      },
      "source": [
        "transformer = VQATransformer(num_layers, d_model, num_heads, dff, vocab_size, pe_input, pe_output,\n",
        "                          pretrained_cnn_type=cnn_type)\n",
        "\n",
        "learning_rate = CustomSchedule(d_model)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, check_point_path, max_to_keep=5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEXuG3G6As7O"
      },
      "source": [
        "@tf.function()\n",
        "def train_step(img, question, kn, tar):\n",
        "    if data_augmentation:\n",
        "        img = aug(img)\n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(question, tar_inp)\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, _ = transformer(question, img, kn, tar_inp,\n",
        "                                     True,\n",
        "                                     enc_padding_mask,\n",
        "                                     combined_mask,\n",
        "                                     dec_padding_mask)\n",
        "        loss = loss_function(tar_real, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(tar_real, predictions)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjyfT_OLAs7P"
      },
      "source": [
        "def evaluate(question, img, kn):\n",
        "    end_token = tf.constant(tokenizer.texts_to_sequences(['<end>']), tf.int32)\n",
        "    output = dec_input = tf.expand_dims([tokenizer.word_index['<start>']], 0)\n",
        "    for i in range(MAX_LENGTH):\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "            question, output)\n",
        "        predictions, attention_weights = transformer(question,\n",
        "                                                     img,\n",
        "                                                     kn,\n",
        "                                                     output,\n",
        "                                                     False,\n",
        "                                                     enc_padding_mask,\n",
        "                                                     combined_mask,\n",
        "                                                     dec_padding_mask)\n",
        "\n",
        "        predictions = predictions[:, -1:, :]\n",
        "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "        if predicted_id == end_token:\n",
        "            return tf.squeeze(output, axis=0), attention_weights\n",
        "        output = tf.concat([output, predicted_id], axis=-1)\n",
        "    return tf.squeeze(output, axis=0), attention_weights"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4fqoypeAs7P"
      },
      "source": [
        "### "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcEUz6KXAs7Q"
      },
      "source": [
        "### Train the Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6DNnkuLAs7Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f04fbde3-d12b-4aef-a5a4-3d9ff1e20359"
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    for (batch, (img_question, tar, _)) in enumerate(batch_train_set):\n",
        "        train_step(img_question[0], img_question[1], img_question[2], tar)\n",
        "        if batch % 50 == 0:\n",
        "            print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
        "                epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
        "    # if (epoch + 1) % 2 == 0:\n",
        "    #     ckpt_save_path = ckpt_manager.save()\n",
        "    #     print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
        "    #                                                         ckpt_save_path))\n",
        "\n",
        "    print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1,\n",
        "                                                train_loss.result(),\n",
        "                                                train_accuracy.result()))\n",
        "\n",
        "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 0.0320 Accuracy 0.1009\n",
            "Epoch 1 Batch 50 Loss 0.0229 Accuracy 0.0950\n",
            "Epoch 1 Batch 100 Loss 0.0225 Accuracy 0.0959\n",
            "Epoch 1 Loss 0.0230 Accuracy 0.0964\n",
            "Time taken for 1 epoch: 114.05688762664795 secs\n",
            "\n",
            "Epoch 2 Batch 0 Loss 0.0274 Accuracy 0.1004\n",
            "Epoch 2 Batch 50 Loss 0.0230 Accuracy 0.0948\n",
            "Epoch 2 Batch 100 Loss 0.0218 Accuracy 0.0959\n",
            "Epoch 2 Loss 0.0225 Accuracy 0.0963\n",
            "Time taken for 1 epoch: 114.7628288269043 secs\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.0282 Accuracy 0.1004\n",
            "Epoch 3 Batch 50 Loss 0.0232 Accuracy 0.0946\n",
            "Epoch 3 Batch 100 Loss 0.0219 Accuracy 0.0958\n",
            "Epoch 3 Loss 0.0222 Accuracy 0.0963\n",
            "Time taken for 1 epoch: 113.8757996559143 secs\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.0269 Accuracy 0.1000\n",
            "Epoch 4 Batch 50 Loss 0.0223 Accuracy 0.0950\n",
            "Epoch 4 Batch 100 Loss 0.0219 Accuracy 0.0959\n",
            "Epoch 4 Loss 0.0221 Accuracy 0.0965\n",
            "Time taken for 1 epoch: 114.18289566040039 secs\n",
            "\n",
            "Epoch 5 Batch 0 Loss 0.0256 Accuracy 0.1013\n",
            "Epoch 5 Batch 50 Loss 0.0207 Accuracy 0.0954\n",
            "Epoch 5 Batch 100 Loss 0.0200 Accuracy 0.0964\n",
            "Epoch 5 Loss 0.0205 Accuracy 0.0970\n",
            "Time taken for 1 epoch: 114.05422496795654 secs\n",
            "\n",
            "Epoch 6 Batch 0 Loss 0.0201 Accuracy 0.1027\n",
            "Epoch 6 Batch 50 Loss 0.0197 Accuracy 0.0958\n",
            "Epoch 6 Batch 100 Loss 0.0191 Accuracy 0.0968\n",
            "Epoch 6 Loss 0.0195 Accuracy 0.0972\n",
            "Time taken for 1 epoch: 114.19868731498718 secs\n",
            "\n",
            "Epoch 7 Batch 0 Loss 0.0326 Accuracy 0.1004\n",
            "Epoch 7 Batch 50 Loss 0.0205 Accuracy 0.0956\n",
            "Epoch 7 Batch 100 Loss 0.0205 Accuracy 0.0964\n",
            "Epoch 7 Loss 0.0206 Accuracy 0.0970\n",
            "Time taken for 1 epoch: 114.36672973632812 secs\n",
            "\n",
            "Epoch 8 Batch 0 Loss 0.0228 Accuracy 0.1022\n",
            "Epoch 8 Batch 50 Loss 0.0191 Accuracy 0.0959\n",
            "Epoch 8 Batch 100 Loss 0.0188 Accuracy 0.0968\n",
            "Epoch 8 Loss 0.0186 Accuracy 0.0975\n",
            "Time taken for 1 epoch: 114.0900068283081 secs\n",
            "\n",
            "Epoch 9 Batch 0 Loss 0.0168 Accuracy 0.1040\n",
            "Epoch 9 Batch 50 Loss 0.0176 Accuracy 0.0965\n",
            "Epoch 9 Batch 100 Loss 0.0172 Accuracy 0.0973\n",
            "Epoch 9 Loss 0.0172 Accuracy 0.0979\n",
            "Time taken for 1 epoch: 114.39565229415894 secs\n",
            "\n",
            "Epoch 10 Batch 0 Loss 0.0190 Accuracy 0.1036\n",
            "Epoch 10 Batch 50 Loss 0.0180 Accuracy 0.0963\n",
            "Epoch 10 Batch 100 Loss 0.0179 Accuracy 0.0970\n",
            "Epoch 10 Loss 0.0179 Accuracy 0.0977\n",
            "Time taken for 1 epoch: 114.55497241020203 secs\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeRL4kj2gQ7b"
      },
      "source": [
        "ckpt_save_path = ckpt_manager.save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxRzF5C2As7S"
      },
      "source": [
        "### "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCSK2rYKAs7T"
      },
      "source": [
        "### Predicting and Evaluating "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhiKr0CbAs7T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "463b6bb9-cac2-4e19-8b66-e61ddf65ea21"
      },
      "source": [
        "true_answers_list = []\n",
        "predicted_answers_list = []\n",
        "ques_id_list = []\n",
        "print('Start predicting...')\n",
        "for (batch, (img_question, target, ques_id)) in enumerate(batch_test_set):\n",
        "    target = target.numpy()\n",
        "    target = target[0]\n",
        "    true_answer = []\n",
        "    for i in target:\n",
        "        if i == 0:\n",
        "            break\n",
        "        else:\n",
        "            true_answer.append(tokenizer.index_word[i])\n",
        "    true_answer = \" \".join(true_answer[1: -1])\n",
        "\n",
        "    prediction, attention = evaluate(img_question[1], img_question[0], img_question[2])\n",
        "    p = prediction.numpy()\n",
        "    predict_answer = [tokenizer.index_word[i] for i in p][1:]\n",
        "    predict_answer = \" \".join(predict_answer)\n",
        "    true_answers_list.append(true_answer)\n",
        "    predicted_answers_list.append(predict_answer)\n",
        "    ques_id_list.append(ques_id)\n",
        "    print(\"predicted answer: \" + str(batch), end='\\r', flush=True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start predicting...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS0azuFOAs7U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66015d6e-f861-42f2-9b10-ebd37d2aed63"
      },
      "source": [
        "data = {\"true answer\": true_answers_list, \"predicted answer\": predicted_answers_list, \"ques_id\": ques_id_list}\n",
        "df = pd.DataFrame(data)\n",
        "if not pathlib.Path(saving_folder).exists():\n",
        "    pathlib.Path(saving_folder).mkdir(parents=True, exist_ok=True)\n",
        "name = save_result_path\n",
        "df.to_csv(name)\n",
        "print(\"complete writing\", name)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "complete writing ./open_ended_results/transformer/bioelmo/inception_2.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWHLATyYAs7V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "191886e2-7124-4886-8a0a-acbe7d0e2753"
      },
      "source": [
        "scores = AnswerEvaluator(name).evaluate()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 29.19\n",
            "Exact Match: 22.91\n",
            "F1 Score: 28.0\n",
            "BLEU-1: 37.05\n",
            "BLEU-2: 24.52\n",
            "BLEU-3: 17.2\n",
            "BLEU-4: 10.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8A_6p_aJAs7W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}