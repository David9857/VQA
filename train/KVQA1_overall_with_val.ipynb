{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "KVQA1_overall_with_val.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/David9857/VQA/blob/main/train/KVQA1_overall_with_val.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6mdYtS7At_V",
        "outputId": "db84a06f-150e-4c58-f6d8-5a061d7eed47"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fvPQbGRGPV-B"
      },
      "source": [
        "!cp /content/drive/MyDrive/files/data_path.zip /content\n",
        "!unzip data_path.zip \"data/jsons/*\" \"data/pic/*\" \"data/ques_embeddings/bioelmo/*\" \"data/answer_word_frequency.csv\" \"data/answer_word_frequency.xlsx\" -d /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDuBoVBH33Tj"
      },
      "source": [
        "# %%bash\n",
        "# cd /content/drive/MyDrive/data\n",
        "# zip -r knowledge_embs.zip knowledge_embeddings/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XerKDOjK0Mxg"
      },
      "source": [
        "!cp /content/drive/MyDrive/data/knowledge_embs.zip /content/data\n",
        "!unzip /content/data/knowledge_embs.zip -d /content/data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCNEgwH01fAH",
        "outputId": "d2c387ed-a599-4dc0-b786-c2c5b80cd7ba"
      },
      "source": [
        "!ls /content/data/knowledge_embeddings | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32761\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpuAUB3asbLa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b18354e5-44c6-48c4-e853-5b4140917c33"
      },
      "source": [
        "# %cd /content\n",
        "# !unzip data_path.zip \"data/ques_embeddings/bioelmo/*\" -d /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V_GEHO0mf7S4",
        "outputId": "74747d78-9826-4676-c6f7-caf59cfdab7a"
      },
      "source": [
        "pip install pycocoevalcap"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycocoevalcap\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/f9/466f289f1628296b5e368940f89e3cfcfb066d15ddc02ff536dc532b1c93/pycocoevalcap-1.2-py3-none-any.whl (104.3MB)\n",
            "\u001b[K     |████████████████████████████████| 104.3MB 81kB/s \n",
            "\u001b[?25hRequirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from pycocoevalcap) (2.0.2)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.7/dist-packages (from pycocotools>=2.0.2->pycocoevalcap) (0.29.22)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools>=2.0.2->pycocoevalcap) (56.0.0)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools>=2.0.2->pycocoevalcap) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (1.19.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools>=2.0.2->pycocoevalcap) (1.15.0)\n",
            "Installing collected packages: pycocoevalcap\n",
            "Successfully installed pycocoevalcap-1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUXGclx9A7Ax",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3125716e-7b7d-4275-a725-4af92cfeafc0"
      },
      "source": [
        "%cd /content/drive/MyDrive/VQACode"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/VQACode\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heHcKvagAs68"
      },
      "source": [
        "# %cd /content/drive/MyDrive/VQACode-/VQACode\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import time\n",
        "import pathlib\n",
        "from utils.load_data_overall import DataLoader\n",
        "from utils.evaluation import AnswerEvaluator\n",
        "from utils.training_toolkit import CustomSchedule, loss_function\n",
        "from models.Transformer.transformers import VQATransformer\n",
        "from models.Transformer.masks import create_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTM_T69yAs7I"
      },
      "source": [
        "### Set up Arguments"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0Py6WFwAs7J"
      },
      "source": [
        "num_layers=8\n",
        "d_model=512\n",
        "num_heads=8\n",
        "dff=2048\n",
        "maximum_position_encoding=10000\n",
        "EPOCHS = 50\n",
        "batch_size = 64\n",
        "cnn_type = 'resnet'\n",
        "embedding = 'bioelmo'  # choose from ['w2v', 'bioelmo', 'biobert', 'bluebert', 'large_biobert', 'elmo']\n",
        "data_augmentation = True\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJXgN3tzAs7K"
      },
      "source": [
        "####### DO NOT CHANGE VALUES OF THIS BLOCK IF YOU ARE NOT THE DEVELOPER ##########\n",
        "\n",
        "check_point_path = './check_point/transformer/QA/' + embedding +'/' + cnn_type + '_' + str(num_layers)\n",
        "saving_folder = './QA_results/transformer/' + embedding + '/'\n",
        "save_result_path = saving_folder + cnn_type + '_' + str(num_layers) + '.csv'\n",
        "\n",
        "emb_size = 1024\n",
        "pe_output = 36 + 1\n",
        "MAX_LENGTH = pe_output\n",
        "if cnn_type == 'inception':\n",
        "    img_shape = [299, 299]\n",
        "    img_padding = tf.TensorShape([299, 299, 3])\n",
        "if cnn_type in ['resnet', 'resnet_v2', 'dense_net', 'vgg19']:\n",
        "    img_shape = None\n",
        "    img_padding = tf.TensorShape([224, 224, 3])\n",
        "\n",
        "if embedding == 'bioelmo':\n",
        "    pe_input = 38\n",
        "elif embedding == 'elmo':\n",
        "    pe_input = 42\n",
        "elif embedding == 'biobert':\n",
        "    pe_input = 72\n",
        "    emb_size = 768\n",
        "elif embedding == 'bluebert':\n",
        "    pe_input = 69\n",
        "elif embedding == 'large_biobert':\n",
        "    pe_input = 60  \n",
        "elif embedding == 'w2v':\n",
        "    pe_input = 48\n",
        "    emb_size = 200\n",
        "elif embedding == 'bert':\n",
        "    pe_input = 72\n",
        "    emb_size = 1024\n",
        "else:\n",
        "    raise TypeError(\"Wrong embedding type\")\n",
        "    \n",
        "if data_augmentation:\n",
        "    aug = tf.keras.Sequential([tf.keras.layers.experimental.preprocessing.RandomFlip(),\n",
        "                               tf.keras.layers.experimental.preprocessing.RandomRotation(0.05)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6FLQdXIAs7L"
      },
      "source": [
        "#### "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SVDCLOfAs7L"
      },
      "source": [
        "### Create Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nslZKpSaAs7M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93e923fe-05d0-47e9-be06-f9572fa77320"
      },
      "source": [
        "# create train, val, test dataset\n",
        "kn_input = 194\n",
        "\n",
        "data_loader = DataLoader('/content/data', emb_folder=embedding)\n",
        "full_dataset, tokenizer = data_loader.create_dataset('QA')\n",
        "vocab_size=len(tokenizer.index_word) + 1\n",
        "Data_SET_SIZE = len(full_dataset)\n",
        "train_size = int(0.52 * Data_SET_SIZE)\n",
        "val_size = int(0.30 * Data_SET_SIZE)\n",
        "test_size = int(0.18 * Data_SET_SIZE)\n",
        "train_set = full_dataset.take(train_size)\n",
        "val_test_ds = full_dataset.skip(train_size)\n",
        "val_set = val_test_ds.take(val_size)\n",
        "test_ds = val_test_ds.skip(val_size)\n",
        "test_set = test_ds.take(test_size)\n",
        "\n",
        "batch_train_set = train_set.padded_batch(batch_size, padded_shapes=((img_padding, tf.TensorShape([pe_input, emb_size]), tf.TensorShape([kn_input, 1024])),\n",
        "                                            tf.TensorShape([pe_output-1]), []), drop_remainder=True)\n",
        "batch_val_set = val_set.padded_batch(1, padded_shapes=((img_padding, tf.TensorShape([pe_input, emb_size]), tf.TensorShape([kn_input, 1024])),\n",
        "                                                                    tf.TensorShape([pe_output-1]), []), drop_remainder=True)\n",
        "batch_test_set = test_set.padded_batch(1, padded_shapes=((img_padding, tf.TensorShape([pe_input, emb_size]), tf.TensorShape([kn_input, 1024])),\n",
        "                                                         tf.TensorShape([pe_output-1]), []), drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "QA: 32761\n",
            "yes_no: 16332\n",
            "open_ended 16429\n",
            "Load: QA\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbsIenPScgQ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe35f23b-e044-4a1d-da94-d51285dabd80"
      },
      "source": [
        "# for i in enumerate(batch_train_set):\n",
        "#   (batch, (img_question, tar, q_id)) = i\n",
        "#   print(batch,img_question[0].shape,img_question[1].shape,img_question[2].shape,tar.shape,q_id.shape)\n",
        "#   break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 (64, 224, 224, 3) (64, 38, 1024) (64, 155, 1024) (64, 36) (64,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fenPNKce01b"
      },
      "source": [
        "# maxl = 0\n",
        "# for (img_question, tar, q_id) in full_dataset.as_numpy_iterator():\n",
        "#   # print(img_question[0].shape,img_question[1].shape,tar.shape,q_id)\n",
        "#   # print(img_question[2].shape)\n",
        "#   l = img_question[2].shape[0]\n",
        "#   if l > maxl:\n",
        "#     maxl = l\n",
        "# print(maxl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlpYIPVolVGL"
      },
      "source": [
        "# import numpy as np\n",
        "# # validate saved features and calculate max length of all questions\n",
        "# ques_id = 48\n",
        "# emb = np.load('/content/data/ques_embeddings/bioelmo/'+str(ques_id)+'.npy')\n",
        "# # length = emb.shape[0]\n",
        "# print(ques_id,'shape is', emb.shape)        \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZBh6t3pAs7M"
      },
      "source": [
        "### "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cs5vzLoUAs7N"
      },
      "source": [
        "### Define Models and Related Functions "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2HVCXcoAs7N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a89bfa59-ea71-4591-bba2-d47c3502a0c6"
      },
      "source": [
        "transformer = VQATransformer(num_layers, d_model, num_heads, dff, vocab_size, pe_input, pe_output,\n",
        "                          pretrained_cnn_type=cnn_type)\n",
        "\n",
        "learning_rate = CustomSchedule(d_model)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, check_point_path, max_to_keep=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEXuG3G6As7O"
      },
      "source": [
        "@tf.function()\n",
        "def train_step(img, question, kn, tar):\n",
        "    if data_augmentation:\n",
        "        img = aug(img)\n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(question, tar_inp)\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, _ = transformer(question, img, kn, tar_inp,\n",
        "                                     True,\n",
        "                                     enc_padding_mask,\n",
        "                                     combined_mask,\n",
        "                                     dec_padding_mask)\n",
        "        loss = loss_function(tar_real, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(tar_real, predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjyfT_OLAs7P"
      },
      "source": [
        "def evaluate(question, img, kn):\n",
        "    end_token = tf.constant(tokenizer.texts_to_sequences(['<end>']), tf.int32)\n",
        "    output = dec_input = tf.expand_dims([tokenizer.word_index['<start>']], 0)\n",
        "    for i in range(MAX_LENGTH):\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
        "            question, output)\n",
        "        predictions, attention_weights = transformer(question,\n",
        "                                    img,\n",
        "                                    kn,\n",
        "                                    output,\n",
        "                                    False,\n",
        "                                    enc_padding_mask,\n",
        "                                    combined_mask,\n",
        "                                    dec_padding_mask)\n",
        "\n",
        "        predictions = predictions[:, -1:, :]\n",
        "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "        if predicted_id == end_token:\n",
        "            return tf.squeeze(output, axis=0), attention_weights\n",
        "        output = tf.concat([output, predicted_id], axis=-1)\n",
        "    return tf.squeeze(output, axis=0), attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2TEMA996txc"
      },
      "source": [
        "################ADD#################################################################################\n",
        "def get_score(batch_data_set, csv_saving_path): \n",
        "    true_answers_list = []\n",
        "    predicted_answers_list = []\n",
        "    ques_id_list = []\n",
        "    for (batch, (img_question, target, ques_id)) in enumerate(batch_data_set):\n",
        "        target = target.numpy()\n",
        "        target = target[0]\n",
        "        true_answer = []\n",
        "        for i in target:\n",
        "            if i == 0:\n",
        "                break\n",
        "            else:\n",
        "                true_answer.append(tokenizer.index_word[i])\n",
        "        true_answer = \" \".join(true_answer[1: -1])\n",
        "        prediction, attention = evaluate(img_question[1], img_question[0], img_question[2])\n",
        "        p = prediction.numpy()\n",
        "        # print('an1:',p)\n",
        "        predict_answer = [tokenizer.index_word[i] for i in p][1:]\n",
        "        # print('an2:',predict_answer)\n",
        "        predict_answer = \" \".join(predict_answer)\n",
        "        true_answers_list.append(true_answer)\n",
        "        predicted_answers_list.append(predict_answer)\n",
        "        ques_id_list.append(ques_id)\n",
        "    # print('answer list:',predicted_answers_list)\n",
        "    data = {\"true answer\": true_answers_list, \"predicted answer\": predicted_answers_list, \"ques_id\": ques_id_list}\n",
        "    df = pd.DataFrame(data)\n",
        "    if not pathlib.Path(saving_folder).exists():\n",
        "        pathlib.Path(saving_folder).mkdir(parents=True, exist_ok=True)\n",
        "    df.to_csv(csv_saving_path)\n",
        "    # print(\"complete writing\", csv_saving_path)\n",
        "    return AnswerEvaluator(csv_saving_path).evaluate()\n",
        "##################ADD#################################################################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z4fqoypeAs7P"
      },
      "source": [
        "### "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xcEUz6KXAs7Q"
      },
      "source": [
        "### Train the Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ofuhyaEz2oks",
        "outputId": "3ca8ef14-66f4-451b-a496-8f957f5ca049"
      },
      "source": [
        "ckpt_manager.restore_or_initialize()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./check_point/transformer/QA/bioelmo/resnet_8/ckpt-1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6DNnkuLAs7Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9f00317-1312-4212-dc8c-3a247fe184c9"
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    for (batch, (img_question, tar, _)) in enumerate(batch_train_set):\n",
        "        train_step(img_question[0], img_question[1], img_question[2], tar)\n",
        "        # if batch % 50 == 0:\n",
        "        #     print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
        "        #         epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
        "    print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(epoch + 1,\n",
        "                                        train_loss.result(),\n",
        "                                        train_accuracy.result()))\n",
        "  ##################Change#################################################################################\n",
        "    # if (epoch+1) % 10 == 0:\n",
        "    #   csv_saving_path = saving_folder + 'val' + str(epoch) + '.csv'\n",
        "    #   score = get_score(batch_val_set, csv_saving_path)\n",
        "    #   model_accuracy = score['Accuracy']\n",
        "    #   # if model_accuracy > accuracy:\n",
        "    #   print('Validation Accuracy',model_accuracy)\n",
        "    #   # ckpt_save_path = ckpt_manager.save()\n",
        "    #   # accuracy = model_accuracy       \n",
        "##################Change#################################################################################\n",
        "\n",
        "    # if (epoch + 1) % 2 == 0:\n",
        "    #     ckpt_save_path = ckpt_manager.save()\n",
        "    #     print ('Saving checkpoint for epoch {} at {}'.format(epoch+1,\n",
        "    #                                                         ckpt_save_path))\n",
        "\n",
        "    # print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Loss 0.3867 Accuracy 0.0298\n",
            "Epoch 2 Loss 0.2521 Accuracy 0.0439\n",
            "Epoch 3 Loss 0.2277 Accuracy 0.0458\n",
            "Epoch 4 Loss 0.2128 Accuracy 0.0467\n",
            "Epoch 5 Loss 0.2013 Accuracy 0.0473\n",
            "Epoch 6 Loss 0.1945 Accuracy 0.0474\n",
            "Epoch 7 Loss 0.2002 Accuracy 0.0422\n",
            "Epoch 8 Loss 0.2218 Accuracy 0.0301\n",
            "Epoch 9 Loss 0.1948 Accuracy 0.0434\n",
            "Epoch 10 Loss 0.1822 Accuracy 0.0460\n",
            "Epoch 11 Loss 0.1767 Accuracy 0.0466\n",
            "Epoch 12 Loss 0.1751 Accuracy 0.0465\n",
            "Epoch 13 Loss 0.1798 Accuracy 0.0458\n",
            "Epoch 14 Loss 0.1732 Accuracy 0.0459\n",
            "Epoch 15 Loss 0.1876 Accuracy 0.0444\n",
            "Epoch 16 Loss 0.1846 Accuracy 0.0444\n",
            "Epoch 17 Loss 0.1751 Accuracy 0.0446\n",
            "Epoch 18 Loss 0.1668 Accuracy 0.0453\n",
            "Epoch 19 Loss 0.1594 Accuracy 0.0458\n",
            "Epoch 20 Loss 0.1515 Accuracy 0.0464\n",
            "Epoch 21 Loss 0.1457 Accuracy 0.0466\n",
            "Epoch 22 Loss 0.1385 Accuracy 0.0474\n",
            "Epoch 23 Loss 0.1326 Accuracy 0.0479\n",
            "Epoch 24 Loss 0.1272 Accuracy 0.0484\n",
            "Epoch 25 Loss 0.1220 Accuracy 0.0489\n",
            "Epoch 26 Loss 0.1171 Accuracy 0.0495\n",
            "Epoch 27 Loss 0.1136 Accuracy 0.0500\n",
            "Epoch 28 Loss 0.1099 Accuracy 0.0503\n",
            "Epoch 29 Loss 0.1072 Accuracy 0.0508\n",
            "Epoch 30 Loss 0.1049 Accuracy 0.0508\n",
            "Epoch 31 Loss 0.1003 Accuracy 0.0516\n",
            "Epoch 32 Loss 0.0989 Accuracy 0.0518\n",
            "Epoch 33 Loss 0.0959 Accuracy 0.0524\n",
            "Epoch 34 Loss 0.0941 Accuracy 0.0527\n",
            "Epoch 35 Loss 0.0921 Accuracy 0.0529\n",
            "Epoch 36 Loss 0.0904 Accuracy 0.0534\n",
            "Epoch 37 Loss 0.0882 Accuracy 0.0537\n",
            "Epoch 38 Loss 0.0867 Accuracy 0.0541\n",
            "Epoch 39 Loss 0.0853 Accuracy 0.0543\n",
            "Epoch 40 Loss 0.0840 Accuracy 0.0545\n",
            "Epoch 41 Loss 0.0824 Accuracy 0.0548\n",
            "Epoch 42 Loss 0.0809 Accuracy 0.0549\n",
            "Epoch 43 Loss 0.0793 Accuracy 0.0553\n",
            "Epoch 44 Loss 0.0785 Accuracy 0.0555\n",
            "Epoch 45 Loss 0.0773 Accuracy 0.0558\n",
            "Epoch 46 Loss 0.0753 Accuracy 0.0559\n",
            "Epoch 47 Loss 0.0754 Accuracy 0.0561\n",
            "Epoch 48 Loss 0.0742 Accuracy 0.0563\n",
            "Epoch 49 Loss 0.0740 Accuracy 0.0565\n",
            "Epoch 50 Loss 0.0730 Accuracy 0.0566\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeRL4kj2gQ7b"
      },
      "source": [
        "ckpt_save_path = ckpt_manager.save()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TPcYqqQol_sO",
        "outputId": "5a250127-4f0d-45e6-c144-5d7d6fdb9ecf"
      },
      "source": [
        "ckpt_save_path"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'./check_point/transformer/QA/bioelmo/resnet_8/ckpt-1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxRzF5C2As7S"
      },
      "source": [
        "### "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCSK2rYKAs7T"
      },
      "source": [
        "### Predicting and Evaluating "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LhiKr0CbAs7T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b00d52a-8322-4a5c-e4ba-167e6aeffa4a"
      },
      "source": [
        "true_answers_list = []\n",
        "predicted_answers_list = []\n",
        "ques_id_list = []\n",
        "print('Start predicting...')\n",
        "for (batch, (img_question, target, ques_id)) in enumerate(batch_test_set):\n",
        "    target = target.numpy()\n",
        "    target = target[0]\n",
        "    true_answer = []\n",
        "    for i in target:\n",
        "        if i == 0:\n",
        "            break\n",
        "        else:\n",
        "            true_answer.append(tokenizer.index_word[i])\n",
        "    true_answer = \" \".join(true_answer[1: -1])\n",
        "\n",
        "    prediction, attention = evaluate(img_question[1], img_question[0], img_question[2])\n",
        "    p = prediction.numpy()\n",
        "    predict_answer = [tokenizer.index_word[i] for i in p][1:]\n",
        "    predict_answer = \" \".join(predict_answer)\n",
        "    true_answers_list.append(true_answer)\n",
        "    predicted_answers_list.append(predict_answer)\n",
        "    ques_id_list.append(ques_id)\n",
        "    print(\"predicted answer: \" + str(batch), end='\\r', flush=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start predicting...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS0azuFOAs7U"
      },
      "source": [
        "data = {\"true answer\": true_answers_list, \"predicted answer\": predicted_answers_list, \"ques_id\": ques_id_list}\n",
        "df = pd.DataFrame(data)\n",
        "if not pathlib.Path(saving_folder).exists():\n",
        "    pathlib.Path(saving_folder).mkdir(parents=True, exist_ok=True)\n",
        "name = save_result_path\n",
        "df.to_csv(name)\n",
        "print(\"complete writing\", name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWHLATyYAs7V"
      },
      "source": [
        "scores = AnswerEvaluator(name).evaluate()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}